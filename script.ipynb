{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/atharav/.local/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import mlflow\n",
    "import mlflow.pytorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "import torch.onnx\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a simple neural network\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.fc1 = nn.Linear(28 * 28, 128)\n",
    "        self.fc2 = nn.Linear(128, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = torch.relu(self.fc1(x))\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training settings\n",
    "batch_size = 64\n",
    "epochs = 5\n",
    "lr = 0.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to ../data/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9912422/9912422 [00:37<00:00, 267823.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to ../data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 28881/28881 [00:00<00:00, 94504.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/train-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1648877/1648877 [00:06<00:00, 250060.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-images-idx3-ubyte.gz to ../data/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Failed to download (trying next):\n",
      "HTTP Error 403: Forbidden\n",
      "\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4542/4542 [00:00<00:00, 5011978.10it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ../data/MNIST/raw/t10k-labels-idx1-ubyte.gz to ../data/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Data loader\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    datasets.MNIST('../data', train=True, download=True,\n",
    "                   transform=transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])),\n",
    "    batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_log_model():\n",
    "    # Initialize model, loss function, optimizer\n",
    "    model = SimpleNN()\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "\n",
    "    # Start MLflow run\n",
    "    with mlflow.start_run() as run:\n",
    "        mlflow.log_param(\"batch_size\", batch_size)\n",
    "        mlflow.log_param(\"epochs\", epochs)\n",
    "        mlflow.log_param(\"learning_rate\", lr)\n",
    "        \n",
    "        for epoch in range(1, epochs + 1):\n",
    "            model.train()\n",
    "            epoch_loss = 0\n",
    "            for batch_idx, (data, target) in enumerate(train_loader):\n",
    "                optimizer.zero_grad()\n",
    "                output = model(data)\n",
    "                loss = criterion(output, target)\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                \n",
    "                epoch_loss += loss.item()\n",
    "                \n",
    "                if batch_idx % 100 == 0:\n",
    "                    print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '\n",
    "                          f'({100. * batch_idx / len(train_loader):.0f}%)]\\tLoss: {loss.item():.6f}')\n",
    "            \n",
    "            # Log metrics to MLflow\n",
    "            avg_loss = epoch_loss / len(train_loader)\n",
    "            mlflow.log_metric(\"avg_loss\", avg_loss, step=epoch)\n",
    "\n",
    "        # Log the model to MLflow\n",
    "        mlflow.pytorch.log_model(model, \"model\")\n",
    "\n",
    "        # Log example input and output\n",
    "        example_input = torch.randn(1, 1, 28, 28)\n",
    "        example_output = model(example_input)\n",
    "        torch.save(example_input, \"example_input.pt\")\n",
    "        torch.save(example_output, \"example_output.pt\")\n",
    "        mlflow.log_artifact(\"example_input.pt\")\n",
    "        mlflow.log_artifact(\"example_output.pt\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_onnx(model):\n",
    "    # Create a dummy input for model export\n",
    "    dummy_input = torch.randn(1, 1, 28, 28)\n",
    "    # Export the model to ONNX format\n",
    "    torch.onnx.export(model, dummy_input, \"model.onnx\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_triton_repository():\n",
    "    # Create necessary directories for Triton\n",
    "    os.makedirs(\"model_repository/mnist_model/1\", exist_ok=True)\n",
    "    # Move the ONNX model to the correct location\n",
    "    shutil.move(\"model.onnx\", \"model_repository/mnist_model/1/model.onnx\")\n",
    "\n",
    "    # Update the config.pbtxt file with correct input/output names\n",
    "    input_name = \"onnx::Flatten_0\"\n",
    "    output_name = \"8\"\n",
    "\n",
    "    with open(\"model_repository/mnist_model/config.pbtxt\", \"w\") as f:\n",
    "        f.write(f\"\"\"\n",
    "name: \"mnist_model\"\n",
    "platform: \"onnxruntime_onnx\"\n",
    "max_batch_size: 1\n",
    "input [\n",
    "  {{\n",
    "    name: \"{input_name}\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 1, 28, 28 ]\n",
    "  }}\n",
    "]\n",
    "output [\n",
    "  {{\n",
    "    name: \"{output_name}\"\n",
    "    data_type: TYPE_FP32\n",
    "    dims: [ 10 ]\n",
    "  }}\n",
    "]\n",
    "        \"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.335581\n",
      "Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.036063\n",
      "Train Epoch: 1 [12800/60000 (21%)]\tLoss: 0.637821\n",
      "Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.466662\n",
      "Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.499840\n",
      "Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.552889\n",
      "Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.466811\n",
      "Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.510484\n",
      "Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.462072\n",
      "Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.194517\n",
      "Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.426510\n",
      "Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.341626\n",
      "Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.368131\n",
      "Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.240365\n",
      "Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.179184\n",
      "Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.233730\n",
      "Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.320385\n",
      "Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.280227\n",
      "Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.355032\n",
      "Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.120695\n",
      "Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.305205\n",
      "Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.330485\n",
      "Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.143161\n",
      "Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.350905\n",
      "Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.170342\n",
      "Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.383525\n",
      "Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.482927\n",
      "Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.387684\n",
      "Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.228379\n",
      "Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.259870\n",
      "Train Epoch: 4 [0/60000 (0%)]\tLoss: 0.277723\n",
      "Train Epoch: 4 [6400/60000 (11%)]\tLoss: 0.209737\n",
      "Train Epoch: 4 [12800/60000 (21%)]\tLoss: 0.313682\n",
      "Train Epoch: 4 [19200/60000 (32%)]\tLoss: 0.338203\n",
      "Train Epoch: 4 [25600/60000 (43%)]\tLoss: 0.236443\n",
      "Train Epoch: 4 [32000/60000 (53%)]\tLoss: 0.182615\n",
      "Train Epoch: 4 [38400/60000 (64%)]\tLoss: 0.150150\n",
      "Train Epoch: 4 [44800/60000 (75%)]\tLoss: 0.177494\n",
      "Train Epoch: 4 [51200/60000 (85%)]\tLoss: 0.096526\n",
      "Train Epoch: 4 [57600/60000 (96%)]\tLoss: 0.135465\n",
      "Train Epoch: 5 [0/60000 (0%)]\tLoss: 0.149768\n",
      "Train Epoch: 5 [6400/60000 (11%)]\tLoss: 0.237555\n",
      "Train Epoch: 5 [12800/60000 (21%)]\tLoss: 0.120271\n",
      "Train Epoch: 5 [19200/60000 (32%)]\tLoss: 0.223493\n",
      "Train Epoch: 5 [25600/60000 (43%)]\tLoss: 0.215090\n",
      "Train Epoch: 5 [32000/60000 (53%)]\tLoss: 0.171048\n",
      "Train Epoch: 5 [38400/60000 (64%)]\tLoss: 0.272870\n",
      "Train Epoch: 5 [44800/60000 (75%)]\tLoss: 0.271041\n",
      "Train Epoch: 5 [51200/60000 (85%)]\tLoss: 0.257228\n",
      "Train Epoch: 5 [57600/60000 (96%)]\tLoss: 0.208980\n",
      "Model training, logging, and Triton deployment preparation complete.\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    model = train_and_log_model()\n",
    "    convert_to_onnx(model)\n",
    "    prepare_triton_repository()\n",
    "\n",
    "    print(\"Model training, logging, and Triton deployment preparation complete.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
